# üìñ API Reference - TOFcam

**Documenta√ß√£o t√©cnica completa da biblioteca tofcam.lib para desenvolvedores.**

## üìã **√çndice**

1. [Vis√£o Geral da API](#vis√£o-geral)
2. [Factory Functions](#factory-functions)
3. [M√≥dulo Camera](#m√≥dulo-camera)
4. [M√≥dulo Depth](#m√≥dulo-depth)
5. [M√≥dulo Navigation](#m√≥dulo-navigation)
6. [M√≥dulo Visualization](#m√≥dulo-visualization)
7. [M√≥dulo Web](#m√≥dulo-web)
8. [Configura√ß√µes](#configura√ß√µes)
9. [Tipos de Dados](#tipos-de-dados)
10. [Exemplos de Integra√ß√£o](#exemplos)

---

## üéØ **Vis√£o Geral da API** {#vis√£o-geral}

### **Design Philosophy**
A `tofcam.lib` foi projetada com foco em:
- **Simplicidade:** Factory functions para uso r√°pido
- **Flexibilidade:** Classes completas para customiza√ß√£o
- **Consist√™ncia:** Padr√µes uniformes em toda a API
- **Performance:** Otimiza√ß√µes autom√°ticas

### **Import Patterns**
```python
# Recommended: Factory functions
from tofcam.lib import (
    create_camera_manager,
    create_depth_estimator,
    create_navigator,
    create_render_pipeline,
    TOFConfig
)

# Advanced: Direct imports
from tofcam.lib.camera import CameraManager, CameraConfig
from tofcam.lib.depth import MidasDepthEstimator
from tofcam.lib.navigation import HybridNavigator, NavigationConfig
```

---

## üè≠ **Factory Functions** {#factory-functions}

### **create_camera_manager()**
```python
def create_camera_manager(config: TOFConfig = None) -> CameraManager
```

**Descri√ß√£o:** Cria gerenciador de c√¢meras com configura√ß√£o autom√°tica.

**Par√¢metros:**
- `config` (optional): Configura√ß√£o personalizada

**Retorna:** Inst√¢ncia de `CameraManager`

**Exemplo:**
```python
from tofcam.lib import create_camera_manager

# Uso b√°sico
camera_manager = create_camera_manager()

# Com configura√ß√£o
config = TOFConfig()
config.camera.width = 1280
camera_manager = create_camera_manager(config)
```

### **create_depth_estimator()**
```python
def create_depth_estimator(config: TOFConfig = None) -> MidasDepthEstimator
```

**Descri√ß√£o:** Cria estimador de profundidade MiDaS otimizado.

**Par√¢metros:**
- `config` (optional): Configura√ß√£o do MiDaS

**Retorna:** Inst√¢ncia de `MidasDepthEstimator`

**Exemplo:**
```python
# B√°sico (CPU/GPU autom√°tico)
depth_estimator = create_depth_estimator()

# For√ßar CPU
config = TOFConfig()
config.midas.device = "cpu"
depth_estimator = create_depth_estimator(config)
```

### **create_navigator()**
```python
def create_navigator(navigation_config: NavigationConfig = None) -> HybridNavigator
```

**Descri√ß√£o:** Cria navegador h√≠brido (strategic + reactive).

**Par√¢metros:**
- `navigation_config` (optional): Configura√ß√£o de navega√ß√£o

**Retorna:** Inst√¢ncia de `HybridNavigator`

**Exemplo:**
```python
# Padr√£o
navigator = create_navigator()

# Customizado
nav_config = NavigationConfig()
nav_config.grid_size = (10, 16)
nav_config.safe_distance = 2.0
navigator = create_navigator(nav_config)
```

### **create_render_pipeline()**
```python
def create_render_pipeline(config: TOFConfig = None) -> RenderPipeline
```

**Descri√ß√£o:** Cria pipeline de renderiza√ß√£o otimizado.

**Exemplo:**
```python
render_pipeline = create_render_pipeline()

# Renderizar depth map colorizado
depth_colored = render_pipeline.render_depth_colored(depth_map)
```

### **discover_cameras()**
```python
def discover_cameras() -> List[int]
```

**Descri√ß√£o:** Descobre c√¢meras USB dispon√≠veis no sistema.

**Retorna:** Lista de √≠ndices de c√¢meras funcionais

**Exemplo:**
```python
from tofcam.lib import discover_cameras

cameras = discover_cameras()
print(f"C√¢meras encontradas: {cameras}")  # [0, 2]
```

---

## üìπ **M√≥dulo Camera** {#m√≥dulo-camera}

### **CameraManager**

#### **Construtor**
```python
class CameraManager:
    def __init__(self)
```

#### **M√©todos Principais**

##### **add_camera()**
```python
def add_camera(self, config: CameraConfig) -> bool
```

**Descri√ß√£o:** Adiciona e configura nova c√¢mera.

**Par√¢metros:**
- `config`: Configura√ß√£o da c√¢mera

**Retorna:** `True` se sucesso, `False` se falha

**Exemplo:**
```python
camera_config = CameraConfig(
    index=0,
    width=640,
    height=480,
    fps=30
)
success = camera_manager.add_camera(camera_config)
```

##### **read_frame()**
```python
def read_frame(self, camera_id: int = None) -> Optional[np.ndarray]
```

**Descri√ß√£o:** Captura frame da c√¢mera especificada.

**Par√¢metros:**
- `camera_id` (optional): ID da c√¢mera (None = primeira dispon√≠vel)

**Retorna:** Frame RGB ou `None` se falha

**Exemplo:**
```python
frame = camera_manager.read_frame()
if frame is not None:
    print(f"Frame shape: {frame.shape}")  # (480, 640, 3)
```

##### **close_all()**
```python
def close_all(self) -> None
```

**Descri√ß√£o:** Fecha todas as c√¢meras abertas.

### **CameraConfig**
```python
@dataclass
class CameraConfig:
    index: int = 0
    width: int = 640
    height: int = 480
    fps: int = 30
    use_test_image: bool = False
```

**Campos:**
- `index`: √çndice da c√¢mera USB
- `width/height`: Resolu√ß√£o desejada
- `fps`: Frames por segundo
- `use_test_image`: Usar imagem sint√©tica para testes

---

## üß† **M√≥dulo Depth** {#m√≥dulo-depth}

### **MidasDepthEstimator**

#### **estimate_depth()**
```python
def estimate_depth(self, image: np.ndarray) -> np.ndarray
```

**Descri√ß√£o:** Estima profundidade usando MiDaS neural network.

**Par√¢metros:**
- `image`: Imagem RGB (H, W, 3)

**Retorna:** Mapa de profundidade normalizado (H, W)

**Exemplo:**
```python
# Capturar e processar
frame = camera_manager.read_frame()
depth_map = depth_estimator.estimate_depth(frame)

# depth_map shape: (480, 640)
# Valores: 0.0 (pr√≥ximo) a 1.0 (distante)
```

#### **preprocess_image()**
```python
def preprocess_image(self, image: np.ndarray) -> torch.Tensor
```

**Descri√ß√£o:** Pr√©-processamento para entrada no MiDaS.

#### **postprocess_depth()**
```python
def postprocess_depth(self, depth: torch.Tensor) -> np.ndarray
```

**Descri√ß√£o:** P√≥s-processamento da sa√≠da do MiDaS.

### **Configura√ß√£o MiDaS**
```python
@dataclass
class MidasConfig:
    model_type: str = "MiDaS_small"  # ou "DPT_Large"
    device: str = "auto"             # "cpu", "cuda", "auto"
    optimize: bool = True            # Otimiza√ß√µes de velocidade
    input_size: Tuple[int, int] = (256, 256)
```

---

## üß≠ **M√≥dulo Navigation** {#m√≥dulo-navigation}

### **HybridNavigator**

#### **navigate()**
```python
def navigate(self, depth_map: np.ndarray, mode: NavigationMode = NavigationMode.HYBRID) -> NavigationResult
```

**Descri√ß√£o:** Executa navega√ß√£o h√≠brida em mapa de profundidade.

**Par√¢metros:**
- `depth_map`: Mapa de profundidade normalizado
- `mode`: Modo de navega√ß√£o (STRATEGIC, REACTIVE, HYBRID)

**Retorna:** Resultado completo da navega√ß√£o

**Exemplo:**
```python
# Navega√ß√£o h√≠brida (recomendado)
nav_result = navigator.navigate(depth_map, NavigationMode.HYBRID)

# Acessar resultados
strategic = nav_result.strategic
reactive = nav_result.reactive

print(f"Strategic yaw: {np.rad2deg(strategic.target_yaw_delta):.1f}¬∞")
print(f"Reactive urgency: {reactive.urgency:.3f}")
```

### **ZoneMapper**

#### **create_strategic_grid()**
```python
def create_strategic_grid(self, depth_map: np.ndarray) -> ZoneGrid
```

**Descri√ß√£o:** Cria grid estrat√©gico para planejamento.

#### **create_reactive_grid()**
```python
def create_reactive_grid(self, depth_map: np.ndarray) -> ZoneGrid
```

**Descri√ß√£o:** Cria grid reativo para desvio de obst√°culos.

### **NavigationResult**
```python
@dataclass
class NavigationResult:
    mode: NavigationMode
    strategic: Optional[StrategicPlan] = None
    reactive: Optional[ReactiveCommand] = None
    timestamp: float = field(default_factory=time.time)
```

### **StrategicPlan**
```python
@dataclass
class StrategicPlan:
    target_yaw_delta: float      # Radianos, ¬±œÄ
    confidence: float            # 0.0 - 1.0
    min_distance_ahead: float    # Metros
    recommended_speed: float     # 0.0 - 1.0
    best_column: int            # Coluna escolhida no grid
    column_scores: List[float]   # Scores de todas as colunas
```

### **ReactiveCommand**
```python
@dataclass
class ReactiveCommand:
    yaw_delta: float            # Corre√ß√£o de dire√ß√£o
    forward_scale: float        # Fator de velocidade 0.0-1.0
    emergency_brake: bool       # Freio de emerg√™ncia
    urgency: float             # N√≠vel de urg√™ncia 0.0-1.0
```

---

## üé® **M√≥dulo Visualization** {#m√≥dulo-visualization}

### **RenderPipeline**

#### **render_depth_colored()**
```python
def render_depth_colored(self, depth_map: np.ndarray, colormap: str = "plasma") -> np.ndarray
```

**Descri√ß√£o:** Renderiza mapa de profundidade com cores.

**Par√¢metros:**
- `depth_map`: Mapa de profundidade normalizado
- `colormap`: Nome do colormap OpenCV

**Retorna:** Imagem colorizada (H, W, 3)

#### **render_strategic_overlay()**
```python
def render_strategic_overlay(self, 
    image: np.ndarray, 
    grid: ZoneGrid, 
    nav_result: NavigationResult
) -> np.ndarray
```

**Descri√ß√£o:** Renderiza overlay estrat√©gico sobre imagem.

#### **render_complete_analysis()**
```python
def render_complete_analysis(self, analysis_frame: AnalysisFrame) -> np.ndarray
```

**Descri√ß√£o:** Renderiza an√°lise completa em uma imagem.

### **Colormaps Dispon√≠veis**
- `"plasma"`: Roxo ‚Üí Amarelo (padr√£o)
- `"viridis"`: Azul ‚Üí Verde ‚Üí Amarelo
- `"hot"`: Preto ‚Üí Vermelho ‚Üí Amarelo
- `"jet"`: Azul ‚Üí Verde ‚Üí Amarelo ‚Üí Vermelho
- `"gray"`: Escala de cinza

---

## üåê **M√≥dulo Web** {#m√≥dulo-web}

### **WebServer**

#### **Construtor**
```python
class WebServer:
    def __init__(self, host: str = "127.0.0.1", port: int = 8081)
```

#### **run()**
```python
def run(self, debug: bool = False) -> None
```

**Descri√ß√£o:** Inicia servidor web Flask.

### **WebIntegration**
```python
class WebIntegration:
    def __init__(self, tof_analyzer: TOFAnalyzer)
    
    def get_video_stream(self) -> bytes
    def get_depth_stream(self) -> bytes
    def get_metrics(self) -> Dict
```

**Exemplo de Uso:**
```python
from tofcam.lib.web import WebServer
from tofcam.lib import create_tof_analyzer

# Criar analyzer
analyzer = create_tof_analyzer()

# Configurar servidor web
server = WebServer(host="0.0.0.0", port=8081)
server.set_analyzer(analyzer)

# Iniciar servidor
server.run()
```

---

## ‚öôÔ∏è **Configura√ß√µes** {#configura√ß√µes}

### **TOFConfig (Principal)**
```python
@dataclass
class TOFConfig:
    camera: CameraConfig = field(default_factory=CameraConfig)
    midas: MidasConfig = field(default_factory=MidasConfig)
    navigation: NavigationConfig = field(default_factory=NavigationConfig)
    visualization: VisualizationConfig = field(default_factory=VisualizationConfig)
    save_frames: bool = False
    output_dir: str = "output_images"
    device: str = "auto"
```

### **NavigationConfig**
```python
@dataclass
class NavigationConfig:
    grid_size: Tuple[int, int] = (8, 12)  # (rows, cols)
    safe_distance: float = 1.5            # metros
    strategic_weight: float = 0.7         # peso strategic vs reactive
    emergency_threshold: float = 0.5      # threshold para emergency brake
    min_confidence: float = 0.3           # confian√ßa m√≠nima strategic
    max_yaw_rate: float = 0.1             # rad/s m√°ximo
```

### **VisualizationConfig**
```python
@dataclass
class VisualizationConfig:
    show_grids: bool = True
    show_metrics: bool = True
    colormap: str = "plasma"
    overlay_alpha: float = 0.6
    grid_line_width: int = 2
    font_scale: float = 0.7
```

---

## üìä **Tipos de Dados** {#tipos-de-dados}

### **Enums**

#### **NavigationMode**
```python
class NavigationMode(Enum):
    STRATEGIC = "strategic"
    REACTIVE = "reactive"
    HYBRID = "hybrid"
```

#### **CellState**
```python
class CellState(Enum):
    FREE = "free"
    OCCUPIED = "occupied"
    WARNING = "warning"
    UNKNOWN = "unknown"
```

#### **ZoneStatus**
```python
class ZoneStatus(Enum):
    SAFE = "safe"
    CAUTION = "caution"
    DANGER = "danger"
    EMERGENCY = "emergency"
```

### **Data Structures**

#### **AnalysisFrame**
```python
@dataclass
class AnalysisFrame:
    timestamp: float
    frame_id: int
    rgb_image: np.ndarray
    depth_map: np.ndarray
    strategic_grid: ZoneGrid
    reactive_grid: ZoneGrid
    navigation_result: NavigationResult
    depth_colored: Optional[np.ndarray] = None
```

#### **ZoneGrid**
```python
@dataclass
class ZoneGrid:
    cells: np.ndarray           # Grid de c√©lulas (H, W)
    cell_size: Tuple[int, int]  # Tamanho de cada c√©lula
    grid_shape: Tuple[int, int] # Shape do grid (rows, cols)
    timestamp: float
```

#### **ZoneCell**
```python
@dataclass
class ZoneCell:
    state: CellState
    distance: float
    confidence: float
    position: Tuple[int, int]
```

---

## üîß **Exemplos de Integra√ß√£o** {#exemplos}

### **Exemplo 1: Pipeline B√°sico**
```python
from tofcam.lib import (
    create_camera_manager,
    create_depth_estimator,
    create_navigator,
    TOFConfig
)

# Setup
config = TOFConfig()
camera_manager = create_camera_manager(config)
depth_estimator = create_depth_estimator(config)
navigator = create_navigator(config.navigation)

# Pipeline
frame = camera_manager.read_frame()
depth_map = depth_estimator.estimate_depth(frame)
nav_result = navigator.navigate(depth_map)

# Resultados
print(f"Yaw target: {np.rad2deg(nav_result.strategic.target_yaw_delta):.1f}¬∞")
print(f"Confidence: {nav_result.strategic.confidence:.3f}")
```

### **Exemplo 2: Loop de Processamento**
```python
import time

def processing_loop():
    # Setup (uma vez)
    camera_manager = create_camera_manager()
    depth_estimator = create_depth_estimator()
    navigator = create_navigator()
    
    # Loop principal
    while True:
        start_time = time.time()
        
        # Pipeline
        frame = camera_manager.read_frame()
        if frame is None:
            continue
            
        depth_map = depth_estimator.estimate_depth(frame)
        nav_result = navigator.navigate(depth_map, NavigationMode.HYBRID)
        
        # M√©tricas
        processing_time = time.time() - start_time
        fps = 1.0 / processing_time
        
        print(f"FPS: {fps:.1f} | Strategic: {nav_result.strategic.confidence:.3f}")
        
        # Controle de taxa
        time.sleep(max(0, 1/30 - processing_time))  # 30 FPS target

# Executar
processing_loop()
```

### **Exemplo 3: An√°lise com Salvamento**
```python
from tofcam.lib import AnalysisFrame
import cv2
import json

def analyze_and_save(output_dir="analysis_output"):
    # Setup
    camera_manager = create_camera_manager()
    depth_estimator = create_depth_estimator()
    navigator = create_navigator()
    render_pipeline = create_render_pipeline()
    
    frame_count = 0
    
    for i in range(100):  # 100 frames
        # An√°lise
        frame = camera_manager.read_frame()
        depth_map = depth_estimator.estimate_depth(frame)
        nav_result = navigator.navigate(depth_map)
        
        # Criar grids
        strategic_grid = navigator.zone_mapper.create_strategic_grid(depth_map)
        reactive_grid = navigator.zone_mapper.create_reactive_grid(depth_map)
        
        # AnalysisFrame
        analysis = AnalysisFrame(
            timestamp=time.time(),
            frame_id=frame_count,
            rgb_image=frame,
            depth_map=depth_map,
            strategic_grid=strategic_grid,
            reactive_grid=reactive_grid,
            navigation_result=nav_result,
            depth_colored=render_pipeline.render_depth_colored(depth_map)
        )
        
        # Salvar
        frame_dir = f"{output_dir}/frame_{frame_count:04d}"
        os.makedirs(frame_dir, exist_ok=True)
        
        cv2.imwrite(f"{frame_dir}/original.jpg", frame)
        cv2.imwrite(f"{frame_dir}/depth.jpg", analysis.depth_colored)
        
        # Metadata
        metadata = {
            "frame_id": frame_count,
            "timestamp": analysis.timestamp,
            "strategic": {
                "target_yaw_delta": float(nav_result.strategic.target_yaw_delta),
                "confidence": float(nav_result.strategic.confidence)
            } if nav_result.strategic else None,
            "reactive": {
                "urgency": float(nav_result.reactive.urgency),
                "emergency_brake": bool(nav_result.reactive.emergency_brake)
            } if nav_result.reactive else None
        }
        
        with open(f"{frame_dir}/metadata.json", "w") as f:
            json.dump(metadata, f, indent=2)
        
        frame_count += 1
        print(f"Frame {frame_count}/100 processado")

analyze_and_save()
```

### **Exemplo 4: Configura√ß√£o Customizada**
```python
from tofcam.lib.config import *

# Configura√ß√£o completa customizada
config = TOFConfig()

# C√¢mera alta resolu√ß√£o
config.camera.width = 1280
config.camera.height = 720
config.camera.fps = 15  # Reduzir FPS para alta resolu√ß√£o

# MiDaS otimizado
config.midas.model_type = "MiDaS_small"  # Mais r√°pido
config.midas.device = "cuda"  # For√ßar GPU
config.midas.optimize = True

# Navega√ß√£o sensitiva
config.navigation.grid_size = (10, 16)    # Grid maior
config.navigation.safe_distance = 2.0     # Dist√¢ncia maior
config.navigation.emergency_threshold = 0.3  # Mais sensitivo

# Visualiza√ß√£o customizada
config.visualization.colormap = "viridis"
config.visualization.overlay_alpha = 0.8
config.visualization.show_metrics = True

# Usar configura√ß√£o
camera_manager = create_camera_manager(config)
depth_estimator = create_depth_estimator(config)
navigator = create_navigator(config.navigation)
```

---

## üîç **Debugging e Profiling**

### **Logs Detalhados**
```python
import logging
from tofcam.lib.utils import logger

# Ativar debug logs
logger.setLevel(logging.DEBUG)

# Ou via environment variable
import os
os.environ['TOFCAM_LOG_LEVEL'] = 'DEBUG'
```

### **Performance Profiling**
```python
import cProfile
import time

def profile_analysis():
    # Setup
    camera_manager = create_camera_manager()
    depth_estimator = create_depth_estimator()
    navigator = create_navigator()
    
    def single_analysis():
        frame = camera_manager.read_frame()
        depth_map = depth_estimator.estimate_depth(frame)
        nav_result = navigator.navigate(depth_map)
        return nav_result
    
    # Profile
    cProfile.run('single_analysis()', 'tofcam_profile.prof')
    
    # Timing individual
    start = time.time()
    frame = camera_manager.read_frame()
    print(f"Camera: {(time.time() - start)*1000:.1f}ms")
    
    start = time.time()
    depth_map = depth_estimator.estimate_depth(frame)
    print(f"MiDaS: {(time.time() - start)*1000:.1f}ms")
    
    start = time.time()
    nav_result = navigator.navigate(depth_map)
    print(f"Navigation: {(time.time() - start)*1000:.1f}ms")

profile_analysis()
```

---

## üìö **Documenta√ß√£o Relacionada**

- **[User Guide](user-guide.md)** - Manual de uso com exemplos pr√°ticos
- **[Architecture](architecture.md)** - Design e arquitetura do sistema
- **[Quick Start](quick-start.md)** - Comandos essenciais
- **[Installation](installation.md)** - Setup do ambiente

**[‚Üë Voltar ao √≠ndice da documenta√ß√£o](README.md)**