# ðŸ—ï¸ Architecture - TOFcam

**Design e arquitetura do sistema TOFcam para desenvolvedores e contribuidores.**

## ðŸ“‹ **Ãndice**

1. [VisÃ£o Geral](#visÃ£o-geral)
2. [Arquitetura em Camadas](#arquitetura-em-camadas)
3. [Biblioteca Central (tofcam.lib)](#biblioteca-central)
4. [Fluxo de Dados](#fluxo-de-dados)
5. [MÃ³dulos Principais](#mÃ³dulos-principais)
6. [APIs e Interfaces](#apis-e-interfaces)
7. [DecisÃµes de Design](#decisÃµes-de-design)
8. [Como Contribuir](#como-contribuir)

---

## ðŸŽ¯ **VisÃ£o Geral** {#visÃ£o-geral}

O TOFcam Ã© um sistema modular de anÃ¡lise de profundidade em tempo real baseado em:

### **PrincÃ­pios de Design**
- **Modularidade:** Componentes independentes e reutilizÃ¡veis
- **Flexibilidade:** MÃºltiplas interfaces (desktop, web, API)
- **Performance:** OtimizaÃ§Ã£o CPU/GPU com caching inteligente
- **Extensibilidade:** Arquitetura plugÃ¡vel para novos algoritmos

### **Componentes Principais**
```mermaid
graph TD
    A[AplicaÃ§Ãµes] --> B[tofcam.lib]
    B --> C[MiDaS Engine]
    B --> D[Navigation Engine]
    B --> E[Visualization Engine]
    B --> F[Camera Manager]
```

---

## ðŸ›ï¸ **Arquitetura em Camadas** {#arquitetura-em-camadas}

```mermaid
graph TB
    subgraph INTERFACES ["INTERFACES"]
        Desktop["Desktop Interface"]
        Web["Web Interface"]
        Analysis["Analysis Tools"]
    end
    
    subgraph BIBLIOTECA ["BIBLIOTECA"]
        Camera["Camera"]
        Depth["Depth Estimation"]
        Navigation["Navigation"]
    end
    
    subgraph ENGINES ["ENGINES"]
        OpenCV["OpenCV"]
        Neural["MiDaS Neural Network"]
        Threading["Threading Management"]
    end
    
    subgraph HARDWARE ["HARDWARE"]
        USB["USB Cameras"]
        Compute["GPU/CPU Processing"]
    end
    
    Desktop --> Camera
    Web --> Camera
    Analysis --> Depth
    
    Camera --> OpenCV
    Depth --> Neural
    Navigation --> Threading
    
    OpenCV --> USB
    Neural --> Compute
    Threading --> Compute
    
    classDef nodeStyle fill:#ffffff,stroke:#6c757d,stroke-width:1px,color:#212529
    classDef subgraphStyle fill:#f8f9fa,stroke:#343a40,stroke-width:2px
    
    class Desktop,Web,Analysis,Camera,Depth,Navigation,OpenCV,Neural,Threading,USB,Compute nodeStyle
```

### **ðŸŽ¯ PropÃ³sito das Camadas**

#### **ðŸŽ¯ Interfaces de UsuÃ¡rio**
**Para que serve:** Pontos de entrada para diferentes tipos de usuÃ¡rios  
**Responsabilidade:** Apresentar funcionalidades de forma adequada ao contexto de uso

#### **ðŸ”§ Biblioteca Unificada (tofcam.lib)**
**Para que serve:** Centralizar toda lÃ³gica de negÃ³cio em API consistente  
**Responsabilidade:** Eliminar duplicaÃ§Ã£o de cÃ³digo e garantir comportamento uniforme

#### **âš™ï¸ Processamento Core**
**Para que serve:** Executar operaÃ§Ãµes computacionalmente intensivas  
**Responsabilidade:** Otimizar performance atravÃ©s de engines especializados

#### **ðŸ”Œ Recursos FÃ­sicos**
**Para que serve:** Abstrair acesso ao hardware do sistema  
**Responsabilidade:** Gerenciar dispositivos fÃ­sicos e recursos computacionais

### **1. Application Layer**
- **main.py:** Interface desktop com 4 janelas
- **run.py:** Servidor web com streaming
- **main_analyzer.py:** AnÃ¡lise com persistÃªncia
- **demos/:** DemonstraÃ§Ãµes e exemplos

### **2. API Layer (tofcam.lib)**
- **Unified Interface:** API consistente para todos os mÃ³dulos
- **Factory Pattern:** Creators para componentes principais
- **Configuration Management:** Sistema de config unificado

### **3. Engine Layer**
- **MiDaS Integration:** Neural network para depth estimation
- **OpenCV Backend:** Processamento de imagem e cÃ¢meras
- **Threading:** Processamento concorrente otimizado

### **4. Hardware Layer**
- **Camera Abstraction:** Suporte multi-cÃ¢mera USB
- **GPU Acceleration:** CUDA quando disponÃ­vel
- **Display Management:** X11/Wayland/Web fallback

---

## ðŸ“š **Biblioteca Central (tofcam.lib)** {#biblioteca-central}

### **Estrutura Modular**
```python
tofcam/lib/
â”œâ”€â”€ __init__.py          # Exports e factory functions
â”œâ”€â”€ config.py            # ConfiguraÃ§Ãµes e tipos (310 linhas)
â”œâ”€â”€ camera.py            # GestÃ£o de cÃ¢meras (325 linhas)
â”œâ”€â”€ depth.py             # EstimaÃ§Ã£o MiDaS (346 linhas)
â”œâ”€â”€ navigation.py        # Algoritmos de navegaÃ§Ã£o (346 linhas)
â”œâ”€â”€ visualization.py     # Rendering pipeline (674 linhas)
â”œâ”€â”€ web.py               # Interface web (574 linhas)
â””â”€â”€ utils.py             # UtilitÃ¡rios e logging (531 linhas)
```

### **Factory Pattern Implementation**
```python
# API unificada atravÃ©s de factory functions
from tofcam.lib import (
    create_camera_manager,
    create_depth_estimator,
    create_navigator,
    create_render_pipeline
)
```

### **MÃ³dulos por Responsabilidade**

#### **config.py - Tipos e ConfiguraÃ§Ãµes**
```python
# Enums para states e modos
class NavigationMode(Enum):
    STRATEGIC = "strategic"
    REACTIVE = "reactive"  
    HYBRID = "hybrid"

# Dataclasses para estruturas
@dataclass
class AnalysisFrame:
    timestamp: float
    frame_id: int
    rgb_image: np.ndarray
    depth_map: np.ndarray
    # ...
```

#### **camera.py - GestÃ£o de CÃ¢meras**
```python
class CameraManager:
    """Thread-safe multi-camera management"""
    
    def add_camera(self, config: CameraConfig) -> bool
    def read_frame(self, camera_id: int = None) -> np.ndarray
    def close_all(self) -> None
```

#### **depth.py - EstimaÃ§Ã£o de Profundidade**
```python
class MidasDepthEstimator:
    """MiDaS neural network integration"""
    
    def estimate_depth(self, image: np.ndarray) -> np.ndarray
    def preprocess_image(self, image: np.ndarray) -> torch.Tensor
    def postprocess_depth(self, depth: torch.Tensor) -> np.ndarray
```

---

## ðŸ”„ **Fluxo de Dados** {#fluxo-de-dados}

### **Pipeline Principal**
```mermaid
sequenceDiagram
    participant App as Application
    participant CM as CameraManager
    participant DE as DepthEstimator
    participant Nav as Navigator
    participant Viz as Visualization
    
    App->>CM: read_frame()
    CM->>App: RGB image
    App->>DE: estimate_depth(image)
    DE->>App: depth_map
    App->>Nav: navigate(depth_map)
    Nav->>App: navigation_result
    App->>Viz: render(image, depth, nav)
    Viz->>App: visualization
```

### **Processamento Concorrente**
```python
# Exemplo de pipeline otimizado
async def process_frame():
    # 1. Captura (thread dedicada)
    frame = await camera_manager.read_frame_async()
    
    # 2. Depth estimation (GPU se disponÃ­vel)
    depth_task = asyncio.create_task(
        depth_estimator.estimate_depth_async(frame)
    )
    
    # 3. Navigation (CPU, paralelo)
    depth_map = await depth_task
    nav_result = navigator.navigate(depth_map)
    
    # 4. Visualization (thread de render)
    visualization = render_pipeline.render_complete(
        frame, depth_map, nav_result
    )
    
    return AnalysisFrame(...)
```

---

## ðŸ§© **MÃ³dulos Principais** {#mÃ³dulos-principais}

### **1. Camera Management**
**Arquivo:** `camera.py`

**Responsabilidades:**
- Descoberta automÃ¡tica de cÃ¢meras USB
- GestÃ£o thread-safe de mÃºltiplas cÃ¢meras
- ConfiguraÃ§Ã£o de resoluÃ§Ã£o/FPS
- Fallback para imagens de teste

**Classes Principais:**
- `CameraSource`: CÃ¢mera individual
- `CameraManager`: GestÃ£o multi-cÃ¢mera
- `CameraConfig`: ConfiguraÃ§Ã£o de cÃ¢mera

### **2. Depth Estimation**
**Arquivo:** `depth.py`

**Responsabilidades:**
- IntegraÃ§Ã£o com MiDaS neural network
- PrÃ©/pÃ³s-processamento de imagens
- OtimizaÃ§Ã£o CPU/GPU automÃ¡tica
- Cache de modelos para performance

**Classes Principais:**
- `MidasDepthEstimator`: Engine principal
- `DepthProcessor`: PÃ³s-processamento
- `ModelManager`: Cache e loading

### **3. Navigation Algorithms**
**Arquivo:** `navigation.py`

**Responsabilidades:**
- Strategic navigation (planejamento global)
- Reactive avoidance (desvio de obstÃ¡culos)
- Zone mapping e anÃ¡lise espacial
- Hybrid navigation modes

**Classes Principais:**
- `ZoneMapper`: Mapeamento espacial
- `StrategicPlanner`: NavegaÃ§Ã£o estratÃ©gica
- `ReactiveAvoider`: Desvio reativo
- `HybridNavigator`: CombinaÃ§Ã£o inteligente

### **4. Visualization**
**Arquivo:** `visualization.py`

**Responsabilidades:**
- Rendering pipeline para mÃºltiplas visualizaÃ§Ãµes
- Overlay de informaÃ§Ãµes de navegaÃ§Ã£o
- ColorizaÃ§Ã£o de depth maps
- Interface grÃ¡fica consistente

**Classes Principais:**
- `RenderPipeline`: Engine de rendering
- `OverlayRenderer`: SobreposiÃ§Ãµes informativas
- `ColorMapper`: Mapeamento de cores

### **5. Web Interface**
**Arquivo:** `web.py`

**Responsabilidades:**
- Servidor Flask para interface web
- Streaming de vÃ­deo em tempo real
- API REST para controle
- WebSocket para updates em tempo real

**Classes Principais:**
- `WebServer`: Servidor Flask
- `VideoStreamer`: Streaming pipeline
- `WebSocketManager`: ComunicaÃ§Ã£o real-time

---

## ðŸ”Œ **APIs e Interfaces** {#apis-e-interfaces}

### **Factory Functions (Recommended)**
```python
from tofcam.lib import (
    create_camera_manager,    # â†’ CameraManager instance
    create_depth_estimator,   # â†’ MidasDepthEstimator
    create_navigator,         # â†’ HybridNavigator
    create_render_pipeline    # â†’ RenderPipeline
)

# Usage
camera_manager = create_camera_manager()
depth_estimator = create_depth_estimator()
```

### **Direct Imports (Advanced)**
```python
from tofcam.lib.camera import CameraManager, CameraConfig
from tofcam.lib.depth import MidasDepthEstimator
from tofcam.lib.navigation import HybridNavigator, NavigationConfig
```

### **Configuration System**
```python
from tofcam.lib import TOFConfig

# ConfiguraÃ§Ã£o centralizada
config = TOFConfig()
config.camera.width = 1280
config.camera.height = 720
config.navigation.grid_size = (8, 12)
config.midas.model_type = "MiDaS_small"
```

---

## ðŸ¤” **DecisÃµes de Design** {#decisÃµes-de-design}

### **1. Por que Factory Pattern?**
- **Simplicidade:** API Ãºnica para criar componentes
- **ConfiguraÃ§Ã£o:** ConfiguraÃ§Ã£o centralized automÃ¡tica
- **Testing:** FÃ¡cil mocking e dependency injection
- **Backwards Compatibility:** MudanÃ§as internas nÃ£o quebram API

### **2. Por que Modular Architecture?**
- **Reusabilidade:** MÃ³dulos independentes
- **Testing:** Testes isolados por mÃ³dulo
- **Performance:** Loading apenas do necessÃ¡rio
- **Maintenance:** MudanÃ§as localizadas

### **3. Por que tofcam.lib?**
- **Zero Duplication:** CÃ³digo centralizado
- **Consistent API:** Interface uniforme
- **Version Control:** Versionamento da biblioteca
- **Distribution:** FÃ¡cil empacotamento

### **4. Threading Strategy**
```python
# Camera capture: Dedicated thread
camera_thread = threading.Thread(target=camera_loop)

# Depth estimation: GPU/CPU optimized
depth_executor = ThreadPoolExecutor(max_workers=2)

# Visualization: Main thread (OpenCV requirement)
# Web server: Flask built-in threading
```

---

## ðŸ¤ **Como Contribuir** {#como-contribuir}

### **Setup de Desenvolvimento**
```bash
# 1. Fork e clone
git clone https://github.com/your-username/TOFcam.git

# 2. Environment
conda activate opencv
pip install -r requirements.txt

# 3. Executar testes
python tests/run_tests.py
```

### **Adicionando Novos MÃ³dulos**

#### **1. Criar mÃ³dulo em tofcam/lib/**
```python
# tofcam/lib/new_module.py
class NewComponent:
    def __init__(self, config):
        self.config = config
    
    def process(self, data):
        return processed_data
```

#### **2. Adicionar factory function**
```python
# tofcam/lib/__init__.py
from .new_module import NewComponent

def create_new_component(config: TOFConfig = None):
    config = config or TOFConfig()
    return NewComponent(config.new_component)
```

#### **3. Adicionar configuraÃ§Ã£o**
```python
# tofcam/lib/config.py
@dataclass
class NewComponentConfig:
    parameter1: str = "default"
    parameter2: int = 42

@dataclass  
class TOFConfig:
    # ... existing configs
    new_component: NewComponentConfig = field(default_factory=NewComponentConfig)
```

### **Testing Guidelines**
```python
# Criar teste em tests/
class TestNewComponent(unittest.TestCase):
    def setUp(self):
        self.component = create_new_component()
    
    def test_process(self):
        result = self.component.process(test_data)
        self.assertIsNotNone(result)
```

### **Extending Navigation Algorithms**
```python
# Herdar de base classes
from tofcam.lib.navigation import BaseNavigator

class CustomNavigator(BaseNavigator):
    def navigate(self, depth_map: np.ndarray) -> NavigationResult:
        # Implementar algoritmo custom
        return NavigationResult(...)

# Registrar no sistema
def create_custom_navigator(config: NavigationConfig = None):
    return CustomNavigator(config)
```

---

## ðŸ“Š **Metrics e Performance**

### **Benchmarks TÃ­picos**
- **Camera Capture:** ~30 FPS (USB 2.0 camera)
- **MiDaS Inference:** ~5-15 FPS (dependente de GPU)
- **Navigation:** ~100+ FPS (processamento CPU)
- **Visualization:** ~30 FPS (limitado por display)

### **Memory Usage**
- **Base System:** ~200MB
- **MiDaS Model:** ~100MB (cached)
- **Per Frame:** ~5-10MB (dependente de resoluÃ§Ã£o)

### **Optimization Points**
1. **GPU Utilization:** MiDaS model loading
2. **Memory Management:** Frame caching strategy
3. **Thread Synchronization:** Producer-consumer queues
4. **Visualization:** Efficient rendering pipeline

---

## ðŸ“– **PrÃ³ximos Passos**

### Para Entender o CÃ³digo
1. **[API Reference](api-reference.md)** - DocumentaÃ§Ã£o detalhada
2. **[User Guide](user-guide.md)** - Exemplos de uso
3. **Explore demos:** `demos/` directory

### Para Contribuir
1. **Issues no GitHub:** Encontre tarefas abertas
2. **Feature Requests:** Proponha melhorias
3. **Pull Requests:** Contribua com cÃ³digo

### Para Performance
1. **Profiling:** Use `cProfile` para analysis
2. **GPU Optimization:** Implementar batching
3. **Memory Optimization:** Implementar streaming

---

**[â†‘ Voltar ao Ã­ndice da documentaÃ§Ã£o](README.md)**